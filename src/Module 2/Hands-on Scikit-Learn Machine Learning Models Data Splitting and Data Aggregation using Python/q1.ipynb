{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: creditcard.csv\n",
      "Error: The file 'creditcard.csv' was not found. Please check the file path.\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Load & Explore the Credit Card Fraud Detection Dataset\n",
    "\n",
    "# Step 1: Load the dataset from a CSV (Assume you have a file named creditcard.csv ).\n",
    "# Step 2: Split the data.\n",
    "# Step 3: Train a Logistic Regression model.\n",
    "# Step 4: Evaluate using ROC AUC score.how \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def load_and_explore_fraud_data(file_path='creditcard.csv', test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Loads, explores, splits, trains a Logistic Regression model, and evaluates\n",
    "    a credit card fraud detection dataset. Includes comprehensive error handling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file containing the dataset.\n",
    "        test_size (float): The proportion of the dataset to use for testing (0.0 to 1.0).\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - roc_auc (float): The ROC AUC score on the test set.\n",
    "            - classification_report_str (str): The classification report on the test set.\n",
    "            - confusion_matrix_array (np.ndarray): The confusion matrix on the test set.\n",
    "            - model (LogisticRegression): The trained Logistic Regression model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Load the dataset\n",
    "        print(f\"Loading dataset from: {file_path}\")\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "\n",
    "        # Basic exploration\n",
    "        print(\"\\n--- Dataset Information ---\")\n",
    "        data.info()\n",
    "        print(\"\\n--- First 5 rows of the dataset ---\")\n",
    "        print(data.head())\n",
    "        print(\"\\n--- Class Distribution ---\")\n",
    "        print(data['Class'].value_counts(normalize=True))\n",
    "\n",
    "        # Check for missing values\n",
    "        if data.isnull().sum().any():\n",
    "            print(\"\\nWarning: Missing values found in the dataset. Consider imputation.\")\n",
    "            print(data.isnull().sum())\n",
    "\n",
    "        # Check for duplicate rows\n",
    "        if data.duplicated().any():\n",
    "            print(\"\\nWarning: Duplicate rows found in the dataset. Consider handling them.\")\n",
    "            print(f\"Number of duplicate rows: {data.duplicated().sum()}\")\n",
    "            data = data.drop_duplicates().reset_index(drop=True)\n",
    "            print(\"Duplicate rows removed.\")\n",
    "\n",
    "        # Step 2: Split the data\n",
    "        print(\"\\n--- Splitting the data ---\")\n",
    "        X = data.drop('Class', axis=1)\n",
    "        y = data['Class']\n",
    "\n",
    "        if X.empty or y.empty:\n",
    "            raise ValueError(\"Features (X) or target (y) are empty after dropping 'Class'.\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "        print(f\"Training set size: {len(X_train)}\")\n",
    "        print(f\"Testing set size: {len(X_test)}\")\n",
    "        print(f\"Class distribution in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
    "        print(f\"Class distribution in testing set:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "        # Step 3: Train a Logistic Regression model\n",
    "        print(\"\\n--- Training Logistic Regression model ---\")\n",
    "        model = LogisticRegression(solver='liblinear', random_state=random_state, class_weight='balanced')\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Model trained successfully.\")\n",
    "\n",
    "        # Step 4: Evaluate the model\n",
    "        print(\"\\n--- Evaluating the model ---\")\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score on the test set: {roc_auc:.4f}\")\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        classification_report_str = classification_report(y_test, y_pred)\n",
    "        print(\"\\nClassification Report on the test set:\")\n",
    "        print(classification_report_str)\n",
    "\n",
    "        confusion_matrix_array = confusion_matrix(y_test, y_pred)\n",
    "        print(\"\\nConfusion Matrix on the test set:\")\n",
    "        print(confusion_matrix_array)\n",
    "\n",
    "        return roc_auc, classification_report_str, confusion_matrix_array, model\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found. Please check the file path.\")\n",
    "        return None, None, None, None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: The file '{file_path}' is empty.\")\n",
    "        return None, None, None, None\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: Failed to parse the file '{file_path}'. Ensure it's a valid CSV format.\")\n",
    "        return None, None, None, None\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    roc_auc, classification_report_str, confusion_matrix_array, trained_model = load_and_explore_fraud_data(file_path='creditcard.csv')\n",
    "\n",
    "    if roc_auc is not None:\n",
    "        print(\"\\n--- Summary ---\")\n",
    "        print(f\"Final ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(\"\\nFinal Classification Report:\")\n",
    "        print(classification_report_str)\n",
    "        print(\"\\nFinal Confusion Matrix:\")\n",
    "        print(confusion_matrix_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
