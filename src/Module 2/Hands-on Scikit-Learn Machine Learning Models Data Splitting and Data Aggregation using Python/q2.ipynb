{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 04:41:37,150 - INFO - Loading dataset from: titanic.csv\n",
      "2025-05-07 04:41:37,152 - ERROR - Error: The file 'titanic.csv' was not found. Please check the file path.\n",
      "2025-05-07 04:41:37,152 - ERROR - An error occurred during the process. Please check the logs for details.\n",
      "2025-05-07 04:41:37,153 - INFO - Total execution time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Feature Engineering & Hyperparameter Tuning on the Titanic Dataset\n",
    "\n",
    "# Step 1: Load the Titanic dataset (Assume you have a file named titanic.csv ).\n",
    "# Step 2: Create features and handle missing values.\n",
    "# Step 3: Train a pipeline using a Random Forest with GridSearchCV.\n",
    "# Step 4: Evaluate the tuned model with cross-validation.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import logging\n",
    "import re  # Import the regular expression module\n",
    "import time\n",
    "\n",
    "# Configure logging for better readability and debugging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def load_data(file_path='titanic.csv'):\n",
    "    \"\"\"\n",
    "    Loads the Titanic dataset from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Loading dataset from: {file_path}\")\n",
    "        data = pd.read_csv(file_path)\n",
    "        logging.info(\"Dataset loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: The file '{file_path}' was not found. Please check the file path.\")\n",
    "        raise\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logging.error(f\"Error: The file '{file_path}' is empty.\")\n",
    "        raise\n",
    "    except pd.errors.ParserError:\n",
    "        logging.error(f\"Error: Failed to parse the file '{file_path}'. Ensure it's a valid CSV format.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "def explore_data(data):\n",
    "    \"\"\"\n",
    "    Explores the dataset by printing information, head, and basic statistics.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input dataset.\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n--- Dataset Exploration ---\")\n",
    "    logging.info(\"Dataset Information:\")\n",
    "    data.info()\n",
    "    logging.info(\"\\nFirst 5 rows of the dataset:\")\n",
    "    logging.info(data.head())\n",
    "    logging.info(\"\\nBasic statistics of the dataset:\")\n",
    "    logging.info(data.describe())\n",
    "\n",
    "    # Check for missing values\n",
    "    logging.info(\"\\nMissing values per column:\")\n",
    "    logging.info(data.isnull().sum())\n",
    "\n",
    "    # Check for duplicate rows\n",
    "    logging.info(f\"\\nNumber of duplicate rows: {data.duplicated().sum()}\")\n",
    "\n",
    "    # Class distribution for the target variable if it exists\n",
    "    if 'Survived' in data.columns:\n",
    "        logging.info(\"\\nClass distribution for 'Survived':\")\n",
    "        logging.info(data['Survived'].value_counts(normalize=True))\n",
    "\n",
    "def feature_engineering(data):\n",
    "    \"\"\"\n",
    "    Performs feature engineering on the Titanic dataset.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transformed dataset.\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n--- Feature Engineering ---\")\n",
    "\n",
    "    # Extract title from Name\n",
    "    def get_title(name):\n",
    "        if pd.isna(name):\n",
    "            return \"Unknown\"\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"Unknown\"\n",
    "\n",
    "    data['Title'] = data['Name'].apply(get_title)\n",
    "    logging.info(\"Extracted titles from 'Name' column.\")\n",
    "\n",
    "    # Grouping titles\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    data['Title'] = data['Title'].replace(['Ms', 'Mlle'], 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    logging.info(\"Grouped titles.\")\n",
    "\n",
    "    # Create FamilySize\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    logging.info(\"Created 'FamilySize' feature.\")\n",
    "\n",
    "    # Create IsAlone\n",
    "    data['IsAlone'] = np.where(data['FamilySize'] == 1, 1, 0)\n",
    "    logging.info(\"Created 'IsAlone' feature.\")\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    logging.info(\"Dropped unnecessary columns: 'PassengerId', 'Name', 'Ticket', 'Cabin'.\")\n",
    "    return data\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Preprocesses the training and testing data using ColumnTransformer.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        X_test (pd.DataFrame): Testing features.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Preprocessed X_train and X_test as numpy arrays, and lists of\n",
    "               numerical and categorical feature names.\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n--- Data Preprocessing ---\")\n",
    "    numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    logging.info(f\"Numerical features: {numerical_features}\")\n",
    "    logging.info(f\"Categorical features: {categorical_features}\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]), numerical_features),\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]), categorical_features)\n",
    "        ])\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    logging.info(\"Data preprocessing completed.\")\n",
    "    return X_train_processed, X_test_processed, numerical_features, categorical_features\n",
    "\n",
    "def train_model(X_train, y_train, param_grid, cv=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest model with hyperparameter tuning using GridSearchCV.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Training features.\n",
    "        y_train (pd.Series): Training target.\n",
    "        param_grid (dict): Parameter grid for GridSearchCV.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "        random_state (int): Random seed.\n",
    "\n",
    "    Returns:\n",
    "        GridSearchCV: The trained GridSearchCV object.\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n--- Model Training ---\")\n",
    "    pipeline = Pipeline(steps=[('classifier', RandomForestClassifier(random_state=random_state))])\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='roc_auc', verbose=1, error_score='raise')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    logging.info(\"Model training completed.\")\n",
    "    return grid_search\n",
    "\n",
    "def evaluate_model(grid_search, X_test, y_test, cv=5):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model using cross-validation and on the test set.\n",
    "\n",
    "    Args:\n",
    "        grid_search (GridSearchCV): The trained GridSearchCV object.\n",
    "        X_test (np.ndarray): Testing features.\n",
    "        y_test (pd.Series): Testing target.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean ROC AUC score from cross-validation, classification report,\n",
    "               confusion matrix, and the best trained model.\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n--- Model Evaluation ---\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    logging.info(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "    cv_scores = cross_val_score(best_model, X_test, y_test, cv=cv, scoring='roc_auc') # Changed to use X_test\n",
    "    mean_cv_roc_auc = np.mean(cv_scores)\n",
    "    logging.info(f\"Mean ROC AUC Score from {cv}-fold cross-validation (test set): {mean_cv_roc_auc:.4f}\") # Changed to test set\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    logging.info(f\"ROC AUC Score on the test set: {test_roc_auc:.4f}\")\n",
    "\n",
    "    classification_report_str = classification_report(y_test, y_pred)\n",
    "    logging.info(\"\\nClassification Report on the test set:\\n%s\", classification_report_str)\n",
    "\n",
    "    confusion_matrix_array = confusion_matrix(y_test, y_pred)\n",
    "    logging.info(\"\\nConfusion Matrix on the test set:\\n%s\", confusion_matrix_array)\n",
    "\n",
    "    return mean_cv_roc_auc, classification_report_str, confusion_matrix_array, best_model\n",
    "\n",
    "def main(file_path='titanic.csv', test_size=0.2, random_state=42, cv=5):\n",
    "    \"\"\"\n",
    "    Main function to load, preprocess, train, and evaluate the Titanic dataset.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        test_size (float): Proportion of the data to use for testing.\n",
    "        random_state (int): Random seed.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        data = load_data(file_path)\n",
    "        explore_data(data)  # Explore the data\n",
    "        data = feature_engineering(data)\n",
    "\n",
    "        # Separate features and target *after* feature engineering\n",
    "        X = data.drop('Survived', axis=1)\n",
    "        y = data['Survived']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "        X_train_processed, X_test_processed, _, _ = preprocess_data(X_train, X_test)\n",
    "\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "\n",
    "        grid_search = train_model(X_train_processed, y_train, param_grid, cv, random_state)\n",
    "        mean_cv_roc_auc, classification_report_str, confusion_matrix_array, best_model = evaluate_model(grid_search, X_test_processed, y_test, cv)\n",
    "\n",
    "        print(\"\\n--- Summary ---\")\n",
    "        print(f\"Mean Cross-Validation ROC AUC Score (Test Set): {mean_cv_roc_auc:.4f}\") # Changed to test set.\n",
    "        print(\"\\nTest Set Performance:\")\n",
    "        print(classification_report_str)\n",
    "        print(confusion_matrix_array)\n",
    "        print(\"\\nBest Model:\\n\", best_model)\n",
    "\n",
    "    except Exception:  # Catch any exception that occurs in the previous steps\n",
    "        logging.error(\"An error occurred during the process. Please check the logs for details.\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(file_path='titanic.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
