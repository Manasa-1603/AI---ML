{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Titanic dataset: titanic.csv\n",
      "Error: The file 'titanic.csv' was not found. Please check the file path.\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Feature Engineering & Hyperparameter Tuning on the Titanic Dataset\n",
    "\n",
    "# Step 1: Load the Titanic dataset (Assume you have a file named titanic.csv ).\n",
    "# Step 2: Create features and handle missing values.\n",
    "# Step 3: Train a pipeline using a Random Forest with GridSearchCV.\n",
    "# Step 4: Evaluate the tuned model with cross-validation.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def load_and_process_titanic_data(file_path='titanic.csv', test_size=0.2, random_state=42, cv=5):\n",
    "    \"\"\"\n",
    "    Loads, preprocesses, performs feature engineering, trains a Random Forest model\n",
    "    with hyperparameter tuning using GridSearchCV, and evaluates the model\n",
    "    on the Titanic dataset.  Includes comprehensive error handling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file containing the Titanic dataset.\n",
    "        test_size (float): Proportion of the data to use for testing.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - roc_auc (float): Mean ROC AUC score from cross-validation.\n",
    "            - classification_report_str (str): Classification report on the test set.\n",
    "            - confusion_matrix_array (np.ndarray): Confusion matrix on the test set.\n",
    "            - best_model (Pipeline): The best trained pipeline.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Load the Titanic dataset\n",
    "        print(f\"Loading Titanic dataset: {file_path}\")\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "\n",
    "        # Basic Exploration\n",
    "        print(\"\\n--- Dataset Information ---\")\n",
    "        data.info()\n",
    "        print(\"\\n--- First 5 rows of the dataset ---\")\n",
    "        print(data.head())\n",
    "\n",
    "        # Check for missing values\n",
    "        if data.isnull().sum().any():\n",
    "            print(\"\\nMissing values found in the dataset. Handling them with imputation.\")\n",
    "            print(data.isnull().sum())\n",
    "\n",
    "        # Check for duplicates\n",
    "        if data.duplicated().any():\n",
    "            print(\"Duplicate rows found.  Removing them.\")\n",
    "            data = data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        # Step 2: Feature Engineering and Data Cleaning\n",
    "        print(\"\\n--- Feature Engineering and Data Cleaning ---\")\n",
    "\n",
    "        # Function to extract title from Name\n",
    "        def get_title(name):\n",
    "            if pd.isna(name):\n",
    "                return \"Unknown\"\n",
    "            title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "            if title_search:\n",
    "                return title_search.group(1)\n",
    "            return \"Unknown\"\n",
    "\n",
    "        # Apply the function to create the Title feature\n",
    "        data['Title'] = data['Name'].apply(get_title)\n",
    "\n",
    "        # Grouping titles\n",
    "        data['Title'] = data['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        data['Title'] = data['Title'].replace(['Ms', 'Mlle'], 'Miss')\n",
    "        data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "        # Create FamilySize\n",
    "        data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "        # Create IsAlone\n",
    "        data['IsAlone'] = np.where(data['FamilySize'] == 1, 1, 0)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "        # Separate features and target\n",
    "        X = data.drop('Survived', axis=1)\n",
    "        y = data['Survived']\n",
    "\n",
    "        if X.empty or y.empty:\n",
    "            raise ValueError(\"Features (X) or target (y) are empty after feature engineering.\")\n",
    "\n",
    "        # Split data *before* preprocessing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "        # Define categorical and numerical features *after* the split\n",
    "        categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "        numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "        # Step 3: Create a pipeline with preprocessing and a Random Forest model\n",
    "        print(\"\\n--- Creating and training the pipeline ---\")\n",
    "        # Define the preprocessor\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', Pipeline(steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]), numerical_features),\n",
    "                ('cat', Pipeline(steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                ]), categorical_features)\n",
    "            ])\n",
    "\n",
    "        # Define the pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', RandomForestClassifier(random_state=random_state))])\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "\n",
    "        # Instantiate GridSearchCV\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='roc_auc', verbose=1, error_score='raise')  # Changed error_score\n",
    "\n",
    "        # Train the model using GridSearchCV\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(\"\\nBest parameters found:\", grid_search.best_params_)\n",
    "\n",
    "        # Step 4: Evaluate the tuned model\n",
    "        print(\"\\n--- Evaluating the tuned model ---\")\n",
    "        # Cross-validation on the *training* data\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "        roc_auc = np.mean(cv_scores)  # Mean CV score\n",
    "        print(f\"Mean ROC AUC Score from {cv}-fold cross-validation (training data): {roc_auc:.4f}\")\n",
    "\n",
    "        # Evaluation on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        test_roc_auc = roc_auc_score(y_test, y_pred_proba) # ROC AUC on test\n",
    "        print(f\"ROC AUC Score on the test set: {test_roc_auc:.4f}\")\n",
    "\n",
    "        classification_report_str = classification_report(y_test, y_pred)\n",
    "        print(\"\\nClassification Report on the test set:\")\n",
    "        print(classification_report_str)\n",
    "\n",
    "        confusion_matrix_array = confusion_matrix(y_test, y_pred)\n",
    "        print(\"\\nConfusion Matrix on the test set:\")\n",
    "        print(confusion_matrix_array)\n",
    "\n",
    "        return roc_auc, classification_report_str, confusion_matrix_array, best_model\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found. Please check the file path.\")\n",
    "        return None, None, None, None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: The file '{file_path}' is empty.\")\n",
    "        return None, None, None, None\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: Failed to parse the file '{file_path}'. Ensure it's a valid CSV format.\")\n",
    "        return None, None, None, None\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    roc_auc, classification_report_str, confusion_matrix_array, best_model = load_and_process_titanic_data(file_path='titanic.csv')\n",
    "\n",
    "    if roc_auc is not None:\n",
    "        print(\"\\n--- Summary ---\")\n",
    "        print(f\"Mean Cross-Validation ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(\"\\nTest Set Performance:\")\n",
    "        print(classification_report_str)\n",
    "        print(confusion_matrix_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
